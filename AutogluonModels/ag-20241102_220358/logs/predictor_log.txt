Beginning AutoGluon training... Time limit = 600s
AutoGluon will save models to 'AutogluonModels\ag-20241102_220358'
=================== System Info ===================
AutoGluon Version:  1.1.2b20241102
Python Version:     3.12.4
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.22631
CPU Count:          22
GPU Count:          0
Memory Avail:       6.67 GB / 31.42 GB (21.2%)
Disk Space Avail:   863.56 GB / 1879.97 GB (45.9%)
===================================================
Setting presets to: best_quality

Fitting with arguments:
{'enable_ensemble': True,
 'eval_metric': MASE,
 'freq': 'D',
 'hyperparameters': {'models': ['NaiveModel',
                                'SeasonalNaiveModel',
                                'AverageModel',
                                'SeasonalAverageModel',
                                'ZeroModel',
                                'ETSModel',
                                'AutoARIMAModel',
                                'AutoETSModel',
                                'AutoCESModel',
                                'ThetaModel',
                                'ADIDAModel',
                                'CrostonClassicModel',
                                'CrostonOptimizedModel',
                                'CrostonSBAModel',
                                'IMAPAModel',
                                'NPTSModel',
                                'DeepARModel',
                                'DLinearModel',
                                'PatchTSTModel',
                                'SimpleFeedForwardModel',
                                'TemporalFusionTransformerModel',
                                'TiDEModel',
                                'WaveNetModel',
                                'DirectTabularModel',
                                'RecursiveTabularModel',
                                'ChronosModel']},
 'known_covariates_names': [],
 'num_val_windows': 2,
 'prediction_length': 2,
 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],
 'random_seed': 123,
 'refit_every_n_windows': 1,
 'refit_full': False,
 'skip_model_selection': False,
 'target': 'Закуплено (количество)',
 'time_limit': 600,
 'verbosity': 2}

train_data with frequency 'None' has been resampled to frequency 'D'.
Provided train_data has 426 rows, 426 time series. Median time series length is 1 (min=1, max=1). 
Time series in train_data are too short for chosen num_val_windows=2. Reducing num_val_windows to 1.
	Removing 426 short time series from train_data. Only series with length >= 7 will be used for training.
	After filtering, train_data has 0 rows, 0 time series. Median time series length is nan (min=nan, max=nan). 
No path specified. Models will be saved in: "AutogluonModels\ag-20241102_220423"
Verbosity: 2 (Standard Logging)
=================== System Info ===================
AutoGluon Version:  1.1.2b20241102
Python Version:     3.12.4
Operating System:   Windows
Platform Machine:   AMD64
Platform Version:   10.0.22631
CPU Count:          22
Memory Avail:       6.44 GB / 31.42 GB (20.5%)
Disk Space Avail:   863.55 GB / 1879.97 GB (45.9%)
===================================================
Presets specified: ['best_quality']
Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)
Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1
DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.
	This is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.
	Running DyStack for up to 150s of the 600s of remaining time (25%).
	Running DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.
